# extractors/ocr_utils.py
"""
M√≥dulo OCR para extra√ß√£o de PDFs escaneados usando Tesseract.
Aplica OCR seletivo apenas quando texto nativo √© insuficiente.
"""
import logging
import os
from typing import Optional, Dict, List
from pdf2image import convert_from_path
import pytesseract
from PIL import Image

def _get_poppler_path() -> Optional[str]:
    """
    Encontra o caminho do poppler no ambiente Nix.
    O poppler_utils pode estar em diferentes locais dependendo da instala√ß√£o.
    Retorna None se n√£o estiver em ambiente Nix ou poppler n√£o estiver instalado.
    """
    nix_store = "/nix/store"
    
    if not os.path.isdir(nix_store):
        return None
    
    possible_paths = [
        "/nix/store/ibb9lajxj2jr8z0bmriqyc43648b7fql-poppler-utils-25.05.0/bin",
    ]
    
    try:
        for nix_dir in os.listdir(nix_store):
            if "poppler" in nix_dir.lower() and "utils" in nix_dir.lower():
                path = f"{nix_store}/{nix_dir}/bin"
                if os.path.exists(path):
                    possible_paths.append(path)
    except (PermissionError, OSError) as e:
        logging.getLogger(__name__).warning(f"[OCR] N√£o foi poss√≠vel listar {nix_store}: {e}")
    
    for path in possible_paths:
        pdftoppm = os.path.join(path, "pdftoppm")
        if os.path.exists(pdftoppm):
            return path
    
    return None

POPPLER_PATH = _get_poppler_path()
if POPPLER_PATH:
    logging.getLogger(__name__).info(f"[OCR] Poppler encontrado: {POPPLER_PATH}")
else:
    logging.getLogger(__name__).warning("[OCR] Poppler n√£o encontrado - OCR usar√° configura√ß√£o padr√£o do sistema")


ANNEX_KEYWORDS = {
    "trct": ["trct", "termo de rescis√£o", "termo rescis√≥rio", "rescisao contrato", "rescis√£o do contrato"],
    "contracheque": ["contracheque", "holerite", "recibo de pagamento", "demonstrativo de pagamento", "folha de pagamento"],
    "documentos": ["documentos", "anexos", "docs", "comprovantes"],
    "ctps": ["ctps", "carteira de trabalho", "carteira profissional"],
    "pis": ["pis", "pasep", "nit"],
}


def extract_pdf_bookmarks(pdf_path: str) -> Dict[str, int]:
    """
    Extrai bookmarks/outlines do PDF e mapeia para n√∫meros de p√°gina.
    
    2025-12-05: Nova fun√ß√£o para extrair mapeamento EXATO de documentos PJe.
    Os PDFs do PJe t√™m bookmarks clic√°veis que apontam diretamente para cada anexo.
    
    Args:
        pdf_path: Caminho do PDF
    
    Returns:
        Dict com {tipo_documento: p√°gina} ex: {"ctps": 19, "trct": 21, "contracheque": 29}
    """
    from PyPDF2 import PdfReader
    
    result = {}
    logger = logging.getLogger(__name__)
    
    try:
        reader = PdfReader(pdf_path)
        outlines = reader.outline if hasattr(reader, 'outline') else None
        
        if not outlines:
            logger.debug("[BOOKMARK] PDF n√£o tem bookmarks")
            return result
        
        logger.info(f"[BOOKMARK] PDF tem {len(outlines)} bookmarks")
        
        for outline in outlines:
            try:
                title = outline.get('/Title', '')
                page_ref = outline.get('/Page')
                
                if not page_ref:
                    continue
                
                # Encontrar n√∫mero da p√°gina
                page_num = None
                for i, page in enumerate(reader.pages, 1):
                    if page.indirect_reference == page_ref:
                        page_num = i
                        break
                
                if not page_num:
                    continue
                
                # Classificar tipo de documento
                title_lower = title.lower()
                
                if "ctps" in title_lower or "carteira de trabalho" in title_lower:
                    if "ctps" not in result:
                        result["ctps"] = page_num
                        logger.info(f"[BOOKMARK] ‚úÖ CTPS ‚Üí p√°gina {page_num}")
                
                elif "trct" in title_lower or ("rescis" in title_lower and "termo" in title_lower):
                    if "trct" not in result:
                        result["trct"] = page_num
                        logger.info(f"[BOOKMARK] ‚úÖ TRCT ‚Üí p√°gina {page_num}")
                
                elif "contracheque" in title_lower or "holerite" in title_lower or "recibo de sal√°rio" in title_lower:
                    if "contracheque" not in result:
                        result["contracheque"] = page_num
                        logger.info(f"[BOOKMARK] ‚úÖ Contracheque ‚Üí p√°gina {page_num}")
                
                elif "ficha de registro" in title_lower:
                    if "ficha_registro" not in result:
                        result["ficha_registro"] = page_num
                        logger.info(f"[BOOKMARK] ‚úÖ Ficha Registro ‚Üí p√°gina {page_num}")
                
                elif "ppp" in title_lower or "perfil profissiogr√°fico" in title_lower:
                    if "ppp" not in result:
                        result["ppp"] = page_num
                        logger.info(f"[BOOKMARK] ‚úÖ PPP ‚Üí p√°gina {page_num}")
            
            except Exception as e:
                continue
        
        if result:
            logger.info(f"[BOOKMARK] üéØ Mapeamento extra√≠do: {result}")
        
        return result
    
    except Exception as e:
        logger.debug(f"[BOOKMARK] Erro ao extrair bookmarks: {e}")
        return result


def parse_toc_from_pdf(pdf_path: str, max_pages: int = 6) -> Dict[str, List[int]]:
    """
    Analisa o sum√°rio (TOC) do PDF para encontrar p√°ginas de anexos trabalhistas.
    
    2025-12-04: OCR Seletivo via Sum√°rio - Extrai links do √≠ndice para TRCT, Contracheques, etc.
    2025-12-05: Corrigido para buscar sum√°rio tamb√©m nas √∫ltimas p√°ginas (PJe coloca no final)
    
    Padr√µes reconhecidos no sum√°rio:
    - "TRCT............45" ou "TRCT - pg 45" ou "TRCT (p√°gina 45)"
    - "Contracheques...........67-72"
    - Links clic√°veis com destino para p√°ginas
    
    Args:
        pdf_path: Caminho do PDF
        max_pages: Quantas p√°ginas iniciais E finais analisar para o sum√°rio (default: 6)
    
    Returns:
        Dict com {categoria: [p√°ginas]} ex: {"trct": [45], "contracheque": [67, 68, 69]}
    """
    import re
    from PyPDF2 import PdfReader
    
    result = {k: [] for k in ANNEX_KEYWORDS.keys()}
    logger = logging.getLogger(__name__)
    
    try:
        reader = PdfReader(pdf_path)
        total_pages = len(reader.pages)
        
        pages_to_read = set()
        for i in range(min(max_pages, total_pages)):
            pages_to_read.add(i)
        for i in range(max(0, total_pages - max_pages), total_pages):
            pages_to_read.add(i)
        
        toc_text = ""
        for i in sorted(pages_to_read):
            page = reader.pages[i]
            text = page.extract_text() or ""
            toc_text += f"\n{text}"
        
        toc_lower = toc_text.lower()
        
        toc_patterns = [
            r'([A-Za-z√Ä-√∫\s]+)[\.\s]{3,}(\d+)',
            r'([A-Za-z√Ä-√∫\s]+)\s*[-‚Äì‚Äî]\s*(?:pg\.?|p\.?|p√°gina)\s*(\d+)',
            r'([A-Za-z√Ä-√∫\s]+)\s*\((?:pg\.?|p\.?|p√°gina)\s*(\d+)\)',
            r'([A-Za-z√Ä-√∫\s]+)\s+(\d{2,3})$',
        ]
        
        for pattern in toc_patterns:
            matches = re.finditer(pattern, toc_text, re.IGNORECASE | re.MULTILINE)
            for match in matches:
                label = match.group(1).strip().lower()
                try:
                    page_num = int(match.group(2))
                    if page_num > 0 and page_num <= total_pages:
                        for category, keywords in ANNEX_KEYWORDS.items():
                            for kw in keywords:
                                if kw in label:
                                    if page_num not in result[category]:
                                        result[category].append(page_num)
                                        logger.debug(f"[TOC_PARSER] '{label}' ‚Üí {category} p√°gina {page_num}")
                                    break
                except ValueError:
                    continue
        
        range_pattern = r'([A-Za-z√Ä-√∫\s]+)[\.\s]{3,}(\d+)\s*[-‚Äì‚Äîa]\s*(\d+)'
        range_matches = re.finditer(range_pattern, toc_text, re.IGNORECASE)
        for match in range_matches:
            label = match.group(1).strip().lower()
            try:
                start_page = int(match.group(2))
                end_page = int(match.group(3))
                if start_page > 0 and end_page <= total_pages and end_page >= start_page:
                    for category, keywords in ANNEX_KEYWORDS.items():
                        for kw in keywords:
                            if kw in label:
                                for pg in range(start_page, min(end_page + 1, start_page + 5)):
                                    if pg not in result[category]:
                                        result[category].append(pg)
                                break
            except ValueError:
                continue
        
        found_any = any(pages for pages in result.values())
        if found_any:
            summary = {k: v for k, v in result.items() if v}
            logger.info(f"[TOC_PARSER] ‚úÖ Sum√°rio encontrado: {summary}")
        else:
            logger.debug("[TOC_PARSER] Nenhum link de anexo trabalhista encontrado no sum√°rio")
        
        return result
        
    except Exception as e:
        logger.warning(f"[TOC_PARSER] Erro ao analisar sum√°rio: {e}")
        return result


def resolve_missing_labor_fields(pdf_path: str, current_data: Dict[str, any], 
                                  missing_fields: List[str]) -> Dict[str, str]:
    """
    Resolve campos trabalhistas faltantes usando OCR seletivo via bookmarks.
    
    2025-12-04: Nova camada de fallback inteligente.
    2025-12-05: OTIMIZA√á√ÉO - Usa bookmarks do PDF primeiro (OCR em 1-2 p√°ginas apenas)
    
    Estrat√©gia (ordem de prioridade):
    1. Extrai bookmarks do PDF (PDFs PJe t√™m links diretos para cada anexo)
    2. Se n√£o encontrar, analisa sum√°rio textual
    3. Se n√£o encontrar, usa heur√≠stica de p√°ginas escaneadas
    4. Aplica OCR apenas nas p√°ginas identificadas (m√≠nimo poss√≠vel)
    
    Args:
        pdf_path: Caminho do PDF
        current_data: Dados j√° extra√≠dos (para n√£o sobrescrever)
        missing_fields: Lista de campos faltantes ["salario", "pis", "data_admissao", etc]
    
    Returns:
        Dict com campos recuperados via OCR seletivo
    """
    import re
    
    result = {}
    logger = logging.getLogger(__name__)
    
    if not missing_fields or not pdf_path:
        return result
    
    logger.info(f"[OCR_SELETIVO] Iniciando fallback para: {missing_fields}")
    
    target_pages = set()
    
    # Mapeamento de campo ‚Üí tipos de documento que cont√™m o campo
    field_to_doc = {
        "salario": ["contracheque", "trct"],
        "data_admissao": ["ctps", "trct"],
        "data_demissao": ["trct"],
        "pis": ["ctps", "trct"],
        "ctps": ["ctps", "trct"],
        "serie_ctps": ["ctps"],
    }
    
    # Carregar todas as fontes de mapeamento uma vez
    bookmarks = extract_pdf_bookmarks(pdf_path)
    toc_pages = parse_toc_from_pdf(pdf_path)
    scanned_pages = None  # Lazy load
    
    if bookmarks:
        logger.info(f"[OCR_SELETIVO] ‚úÖ Bookmarks dispon√≠veis: {bookmarks}")
    if any(v for v in toc_pages.values()):
        logger.info(f"[OCR_SELETIVO] ‚úÖ TOC dispon√≠vel: {toc_pages}")
    
    # ===== ESTRAT√âGIA POR CAMPO: Fallback hier√°rquico para CADA campo =====
    fields_resolved = {}
    
    for field in missing_fields:
        doc_types = field_to_doc.get(field, [])
        page_found = None
        source = None
        
        # PRIORIDADE 1: Tentar bookmarks primeiro
        for doc_type in doc_types:
            if doc_type in bookmarks:
                page_found = bookmarks[doc_type]
                source = f"bookmark:{doc_type}"
                break
        
        # PRIORIDADE 2: Tentar TOC se bookmark n√£o encontrou
        if not page_found:
            for doc_type in doc_types:
                if toc_pages.get(doc_type):
                    page_found = toc_pages[doc_type][0]
                    source = f"toc:{doc_type}"
                    break
        
        # PRIORIDADE 3: Heur√≠stica se nada encontrou (lazy load)
        if not page_found:
            if scanned_pages is None:
                scanned_pages = detect_scanned_pages(pdf_path)
            if scanned_pages:
                # Pegar primeiras 3 + √∫ltimas 2 p√°ginas escaneadas
                first_pages = scanned_pages[:3]
                last_pages = scanned_pages[-2:] if len(scanned_pages) > 3 else []
                heuristic_pages = list(set(first_pages + last_pages))
                if heuristic_pages:
                    page_found = heuristic_pages[0]  # Pegar primeira
                    source = "heuristic"
                    # Adicionar todas as heur√≠sticas para campos n√£o mapeados
                    for hp in heuristic_pages:
                        target_pages.add(hp)
        
        if page_found:
            target_pages.add(page_found)
            fields_resolved[field] = source
            logger.debug(f"[OCR_SELETIVO] {field} ‚Üí p√°gina {page_found} via {source}")
    
    if fields_resolved:
        logger.info(f"[OCR_SELETIVO] Campos mapeados: {fields_resolved}")
    
    if not target_pages:
        logger.debug("[OCR_SUMARIO] Nenhuma p√°gina alvo identificada")
        return result
    
    target_list = sorted(list(target_pages))[:5]
    logger.info(f"[OCR_SUMARIO] üì∑ Aplicando OCR nas p√°ginas: {target_list}")
    
    try:
        texto_ocr = ""
        for page_num in target_list:
            try:
                images = convert_from_path(
                    pdf_path,
                    dpi=200,
                    first_page=page_num,
                    last_page=page_num,
                    poppler_path=POPPLER_PATH
                )
                
                for img in images:
                    img_gray = img.convert('L')
                    config = '--psm 6 -l por+eng'
                    texto_pagina = pytesseract.image_to_string(img_gray, config=config)
                    texto_ocr += f"\n--- P√ÅGINA {page_num} ---\n{texto_pagina}"
                    logger.debug(f"[OCR_SUMARIO] P√°gina {page_num}: {len(texto_pagina)} chars extra√≠dos")
            except Exception as e:
                logger.warning(f"[OCR_SUMARIO] Erro p√°gina {page_num}: {e}")
        
        if not texto_ocr:
            return result
        
        logger.debug(f"[OCR_SUMARIO] Total texto OCR: {len(texto_ocr)} chars")
        
        if "salario" in missing_fields:
            salario_patterns = [
                r'(?:sal[a√°]rio\s*(?:base|contratual|mensal)?|remunera[√ßc][√£a]o(?:\s*mensal)?)[:\s]*R?\$?\s*([\d]{1,3}(?:[.,]\d{3})*[,\.]\d{2})',
                r'(?:maior\s*remunera[√ßc][√£a]o|base\s*de\s*c[a√°]lculo)[:\s]*R?\$?\s*([\d]{1,3}(?:[.,]\d{3})*[,\.]\d{2})',
                r'(?:vencimento|proventos)[:\s]*R?\$?\s*([\d]{1,3}(?:[.,]\d{3})*[,\.]\d{2})',
                r'(?:total\s*bruto|bruto)[:\s]*R?\$?\s*([\d]{1,3}(?:[.,]\d{3})*[,\.]\d{2})',
                r'R\$\s*([\d]{1,3}(?:\.\d{3})*,\d{2})',
            ]
            for pattern in salario_patterns:
                m = re.search(pattern, texto_ocr, re.IGNORECASE)
                if m:
                    val_str = m.group(1).replace('.', '').replace(',', '.')
                    try:
                        val = float(val_str)
                        if 1000 <= val <= 100000:
                            result["salario"] = f"R$ {m.group(1)}"
                            logger.info(f"[OCR_SUMARIO] ‚úÖ Sal√°rio: {result['salario']}")
                            break
                    except:
                        pass
        
        if "data_admissao" in missing_fields:
            admissao_patterns = [
                r'(?:data\s*(?:de\s*)?admiss[√£a]o|admitido\s*em|in[i√≠]cio\s*(?:do\s*)?contrato)[:\s]*(\d{1,2}[/.-]\d{1,2}[/.-]\d{2,4})',
                r'admiss[√£a]o[:\s]*(\d{1,2}[/.-]\d{1,2}[/.-]\d{2,4})',
            ]
            for pattern in admissao_patterns:
                m = re.search(pattern, texto_ocr, re.IGNORECASE)
                if m:
                    result["data_admissao"] = m.group(1)
                    logger.info(f"[OCR_SUMARIO] ‚úÖ Data Admiss√£o: {result['data_admissao']}")
                    break
        
        if "data_demissao" in missing_fields:
            demissao_patterns = [
                r'(?:data\s*(?:de\s*)?(?:demiss[√£a]o|desligamento|sa[i√≠]da|rescis[√£a]o)|demitido\s*em|t[e√©]rmino\s*(?:do\s*)?contrato)[:\s]*(\d{1,2}[/.-]\d{1,2}[/.-]\d{2,4})',
                r'(?:aviso\s*pr[e√©]vio\s*(?:at[e√©]|fim)|[u√∫]ltimo\s*dia\s*trabalhado)[:\s]*(\d{1,2}[/.-]\d{1,2}[/.-]\d{2,4})',
            ]
            for pattern in demissao_patterns:
                m = re.search(pattern, texto_ocr, re.IGNORECASE)
                if m:
                    result["data_demissao"] = m.group(1)
                    logger.info(f"[OCR_SUMARIO] ‚úÖ Data Demiss√£o: {result['data_demissao']}")
                    break
        
        if "pis" in missing_fields:
            pis_patterns = [
                r'(?:PIS|PASEP|NIT|PIS/PASEP)[:\s/]*(\d{3}[.\s]?\d{5}[.\s]?\d{2}[.\s-]?\d)',
                r'\b(\d{3}\.\d{5}\.\d{2}[.-]\d)\b',
                r'\b(\d{11})\b',
            ]
            for pattern in pis_patterns:
                m = re.search(pattern, texto_ocr, re.IGNORECASE)
                if m:
                    pis_raw = re.sub(r'[^\d]', '', m.group(1))
                    if len(pis_raw) == 11:
                        result["pis"] = f"{pis_raw[:3]}.{pis_raw[3:8]}.{pis_raw[8:10]}-{pis_raw[10]}"
                        logger.info(f"[OCR_SUMARIO] ‚úÖ PIS: {result['pis']}")
                        break
        
        if "ctps" in missing_fields:
            ctps_patterns = [
                r'(?:CTPS|Carteira\s*(?:de\s*)?Trabalho)[:\s]*[nN]?[¬∫¬∞]?\s*(\d{5,7})[/\s,]*(?:s[e√©]rie|s√©rie)[:\s]*(\d{3,5})(?:[/\s-]*([A-Z]{2}))?',
                r'[nN]?[¬∫¬∞]?\s*(\d{5,7})[/\s]*[sS][e√©E][rR][iI][eE][:\s]*(\d{3,5})(?:[/\s-]*([A-Z]{2}))?',
            ]
            for pattern in ctps_patterns:
                m = re.search(pattern, texto_ocr, re.IGNORECASE)
                if m:
                    numero = m.group(1)
                    serie = m.group(2)
                    uf = m.group(3) if len(m.groups()) >= 3 and m.group(3) else None
                    if uf:
                        result["ctps"] = f"{numero} s√©rie {serie}-{uf}"
                    else:
                        result["ctps"] = f"{numero} s√©rie {serie}"
                    logger.info(f"[OCR_SUMARIO] ‚úÖ CTPS: {result['ctps']}")
                    break
        
        if result:
            logger.info(f"[OCR_SUMARIO] üéØ Recuperados {len(result)} campos via OCR seletivo: {list(result.keys())}")
        else:
            logger.debug("[OCR_SUMARIO] Nenhum campo recuperado via OCR")
        
        return result
        
    except Exception as e:
        logger.error(f"[OCR_SUMARIO] ‚ùå Erro no OCR seletivo: {e}")
        return result


def detect_scanned_pages(pdf_path: str, min_text_len: int = 200, 
                         search_all: bool = True) -> List[int]:
    """
    Detecta p√°ginas escaneadas/imagens em um PDF usando heur√≠stica robusta.
    
    2025-12-01: Plano Batman - Mapeamento cir√∫rgico para OCR seletivo.
    2025-12-05: Corrigido para buscar em TODO o PDF (n√£o s√≥ √∫ltimas 30%).
               PDFs do PJe t√™m anexos em qualquer posi√ß√£o.
    
    Heur√≠stica: Uma p√°gina √© considerada escaneada/imagem se:
    - Tem menos de 200 caracteres de texto nativo E
    - Cont√©m apenas texto de rodap√© ("Documento assinado eletronicamente...")
    
    Args:
        pdf_path: Caminho do PDF
        min_text_len: M√≠nimo de caracteres para considerar p√°gina como texto (default: 200)
        search_all: Se True, busca em todo o PDF. Se False, s√≥ nas √∫ltimas 30%.
    
    Returns:
        Lista de n√∫meros de p√°ginas escaneadas (1-indexed)
    """
    from PyPDF2 import PdfReader
    
    scanned_pages = []
    logger = logging.getLogger(__name__)
    
    try:
        reader = PdfReader(pdf_path)
        total_pages = len(reader.pages)
        
        # Determinar onde come√ßar a busca
        if search_all:
            start_page = 1
        else:
            start_page = max(1, int(total_pages * 0.7))
        
        for i, page in enumerate(reader.pages, 1):
            if i < start_page:
                continue
            
            text = page.extract_text() or ""
            text_len = len(text.strip())
            
            # P√°gina com menos de 200 chars = prov√°vel imagem/scan
            if text_len < min_text_len:
                scanned_pages.append(i)
                logger.debug(f"[DETECT_SCANNED] P√°gina {i}/{total_pages}: {text_len} chars - ESCANEADA")
        
        if scanned_pages:
            logger.info(f"[DETECT_SCANNED] {len(scanned_pages)} p√°ginas escaneadas encontradas: {scanned_pages}")
        
    except Exception as e:
        logger.debug(f"[DETECT_SCANNED] Erro ao analisar PDF: {e}")
    
    return scanned_pages


def ocr_extract_from_pages(pdf_path: str, pages: List[int]) -> Dict[str, str]:
    """
    Aplica OCR apenas nas p√°ginas espec√≠ficas e extrai campos trabalhistas.
    
    2025-12-01: Plano Batman - OCR cir√∫rgico apenas nas p√°ginas mapeadas.
    
    Args:
        pdf_path: Caminho do PDF
        pages: Lista de n√∫meros de p√°ginas para processar (1-indexed)
    
    Returns:
        Dict com campos extra√≠dos: {"salario": "...", "pis": "...", "ctps": "..."}
    """
    import re
    
    result = {}
    
    if not pages:
        return result
    
    try:
        logger = logging.getLogger(__name__)
        logger.info(f"[OCR_CIRURGICO] Processando {len(pages)} p√°ginas: {pages}")
        
        texto_ocr = ""
        for page_num in pages:
            try:
                images = convert_from_path(
                    pdf_path,
                    dpi=150,
                    first_page=page_num,
                    last_page=page_num,
                    poppler_path=POPPLER_PATH
                )
                
                for img in images:
                    img_gray = img.convert('L')
                    config = '--psm 6 -l por+eng'
                    texto_pagina = pytesseract.image_to_string(img_gray, config=config)
                    texto_ocr += f"\n{texto_pagina}"
            except Exception as e:
                logger.debug(f"[OCR_CIRURGICO] Erro p√°gina {page_num}: {e}")
        
        if not texto_ocr:
            return result
        
        # Extrair sal√°rio
        salario_patterns = [
            r'(?:sal[a√°]rio|remunera[c√ß][a√£]o|vencimento)[:\s]*R?\$?\s*([\d.,]+)',
            r'R\$\s*([\d]{1,3}(?:\.?\d{3})*[,\.]\d{2})',
        ]
        for pattern in salario_patterns:
            m = re.search(pattern, texto_ocr, re.IGNORECASE)
            if m:
                val = m.group(1).replace('.', '').replace(',', '.')
                try:
                    if float(val) > 500:
                        result["salario"] = f"R$ {m.group(1)}"
                        logger.info(f"[OCR_CIRURGICO] Sal√°rio: {result['salario']}")
                        break
                except:
                    pass
        
        # Extrair PIS
        pis_patterns = [
            r'(?:PIS|PASEP|NIT)[:\s/]*(\d{3}[.\s]?\d{5}[.\s]?\d{2}[.\s-]?\d)',
            r'\b(\d{3}\.\d{5}\.\d{2}[.-]\d)\b',
        ]
        for pattern in pis_patterns:
            m = re.search(pattern, texto_ocr, re.IGNORECASE)
            if m:
                pis_raw = m.group(1).replace(' ', '').replace('.', '').replace('-', '')
                if len(pis_raw) == 11:
                    result["pis"] = f"{pis_raw[:3]}.{pis_raw[3:8]}.{pis_raw[8:10]}-{pis_raw[10]}"
                    logger.info(f"[OCR_CIRURGICO] PIS: {result['pis']}")
                    break
        
        # Extrair CTPS (com UF quando dispon√≠vel)
        ctps_patterns = [
            # Formato com UF: "CTPS 1234567 s√©rie 123/RJ" ou "1234567/123/RJ"
            r'(?:CTPS|Carteira)[:\s]*(\d{5,7})[/\s]*(?:s[e√©]rie|s√©rie)[:\s]*(\d{3,5})[/\s-]*([A-Z]{2})',
            r'(\d{5,7})[/\s-]+(\d{3,5})[/\s-]+([A-Z]{2})',
            # Formato sem UF: "CTPS 1234567 s√©rie 123"
            r'(?:CTPS|Carteira)[:\s]*(\d{5,7})[/\s]*(?:s[e√©]rie|s√©rie)[:\s]*(\d{3,5})',
        ]
        for pattern in ctps_patterns:
            m = re.search(pattern, texto_ocr, re.IGNORECASE)
            if m:
                if len(m.groups()) >= 3 and m.group(3):
                    # Com UF
                    result["ctps"] = f"{m.group(1)} s√©rie {m.group(2)}/{m.group(3)}"
                elif len(m.groups()) >= 2:
                    # Sem UF
                    result["ctps"] = f"{m.group(1)} s√©rie {m.group(2)}"
                else:
                    result["ctps"] = m.group(1)
                logger.info(f"[OCR_CIRURGICO] CTPS: {result['ctps']}")
                break
        
        logger.info(f"[OCR_CIRURGICO] ‚úÖ Extra√≠dos {len(result)} campos via OCR cir√∫rgico")
        return result
        
    except Exception as e:
        logging.getLogger(__name__).error(f"[OCR_CIRURGICO] ‚ùå Erro: {e}")
        return result


# Integra√ß√£o com monitor remoto
try:
    from monitor_integration import log_info, log_error
    MONITOR_AVAILABLE = True
except ImportError:
    MONITOR_AVAILABLE = False
    def log_info(msg, region=""): pass
    def log_error(msg, exc=None, region=""): pass

logger = logging.getLogger(__name__)

def is_scanned_pdf(text: str, page_count: int = 1) -> bool:
    """
    Detecta se PDF √© escaneado (densidade de texto baixa).
    
    Args:
        text: Texto extra√≠do do PDF
        page_count: N√∫mero de p√°ginas do PDF
    
    Returns:
        True se densidade < 200 chars/p√°gina (prov√°vel scan)
    """
    if not text or len(text.strip()) == 0:
        return True
    
    densidade = len(text) / page_count if page_count > 0 else 0
    return densidade < 200


def extract_text_with_ocr(pdf_path: str, first_pages: int = 3) -> str:
    """
    Extrai texto usando OCR (Tesseract) nas primeiras p√°ginas do PDF.
    
    Args:
        pdf_path: Caminho do arquivo PDF
        first_pages: N√∫mero de p√°ginas para processar (default: 3)
    
    Returns:
        Texto extra√≠do via OCR
    """
    try:
        logger.info(f"[OCR] Iniciando extra√ß√£o OCR: {pdf_path}")
        if POPPLER_PATH:
            logger.info(f"[OCR] Usando poppler de: {POPPLER_PATH}")
        
        # Converter PDF para imagens (primeiras N p√°ginas)
        images = convert_from_path(
            pdf_path, 
            dpi=300,  # Alta resolu√ß√£o para melhor OCR
            first_page=1,
            last_page=first_pages,
            poppler_path=POPPLER_PATH
        )
        
        logger.info(f"[OCR] Converteu {len(images)} p√°ginas para imagem")
        
        # Aplicar OCR em cada p√°gina
        texto_completo = []
        for i, img in enumerate(images, 1):
            # Pr√©-processamento: converter para escala de cinza
            img_gray = img.convert('L')
            
            # OCR com Tesseract (pt-BR + eng)
            config = '--psm 6 -l por+eng'  # PSM 6 = blocos de texto, portugu√™s + ingl√™s
            texto_pagina = pytesseract.image_to_string(img_gray, config=config)
            
            texto_completo.append(f"\n--- P√ÅGINA {i} (OCR) ---\n{texto_pagina}")
            logger.debug(f"[OCR] P√°gina {i}: {len(texto_pagina)} chars")
        
        texto_final = "\n".join(texto_completo)
        logger.info(f"[OCR] ‚úÖ Extra√ß√£o conclu√≠da: {len(texto_final)} chars total")
        
        return texto_final
        
    except Exception as e:
        logger.error(f"[OCR] ‚ùå Erro ao processar PDF: {e}")
        return ""


def ocr_extract_labor_fields(pdf_path: str, max_pages: int = 8) -> Dict[str, str]:
    """
    Extrai campos trabalhistas cr√≠ticos (sal√°rio, PIS, CTPS) via OCR seletivo.
    
    Faz OCR nas √öLTIMAS p√°ginas do PDF onde geralmente est√£o TRCT/contracheques.
    
    Args:
        pdf_path: Caminho do PDF
        max_pages: M√°ximo de p√°ginas para processar (default: 8)
    
    Returns:
        Dict com campos extra√≠dos: {"salario": "...", "pis": "...", "ctps": "..."}
    """
    import re
    
    result = {}
    
    try:
        from PyPDF2 import PdfReader
        
        reader = PdfReader(pdf_path)
        total_pages = len(reader.pages)
        
        start_page = max(1, total_pages - max_pages + 1)
        
        logger.info(f"[OCR_LABOR] Extraindo campos trabalhistas via OCR: p√°ginas {start_page}-{total_pages}")
        
        images = convert_from_path(
            pdf_path,
            dpi=150,
            first_page=start_page,
            last_page=total_pages,
            poppler_path=POPPLER_PATH
        )
        
        texto_ocr = ""
        for i, img in enumerate(images, start_page):
            img_gray = img.convert('L')
            config = '--psm 6 -l por+eng'
            texto_pagina = pytesseract.image_to_string(img_gray, config=config)
            texto_ocr += f"\n{texto_pagina}"
        
        if not texto_ocr:
            return result
        
        salario_patterns = [
            r'(?:sal[a√°]rio|remunera[c√ß][a√£]o|vencimento)[:\s]*R?\$?\s*([\d.,]+)',
            r'R\$\s*([\d]{1,3}(?:\.?\d{3})*[,\.]\d{2})',
        ]
        for pattern in salario_patterns:
            m = re.search(pattern, texto_ocr, re.IGNORECASE)
            if m:
                val = m.group(1).replace('.', '').replace(',', '.')
                try:
                    if float(val) > 500:
                        result["salario"] = f"R$ {m.group(1)}"
                        logger.info(f"[OCR_LABOR] Sal√°rio: {result['salario']}")
                        break
                except:
                    pass
        
        pis_patterns = [
            r'(?:PIS|PASEP|NIT)[:\s/]*(\d{3}[.\s]?\d{5}[.\s]?\d{2}[.\s-]?\d)',
            r'\b(\d{3}\.\d{5}\.\d{2}[.-]\d)\b',
        ]
        for pattern in pis_patterns:
            m = re.search(pattern, texto_ocr, re.IGNORECASE)
            if m:
                result["pis"] = m.group(1).replace(' ', '').replace('.', '').replace('-', '')
                logger.info(f"[OCR_LABOR] PIS: {result['pis']}")
                break
        
        ctps_patterns = [
            r'(?:CTPS|Carteira)[:\s]*(\d{5,7})[/\s]*(?:s[e√©]rie|s√©rie)[:\s]*(\d{3,5})',
            r'(\d{5,7})[/\s-]+(\d{3,5})[/\s-]*([A-Z]{2})',
        ]
        for pattern in ctps_patterns:
            m = re.search(pattern, texto_ocr, re.IGNORECASE)
            if m:
                if len(m.groups()) >= 2:
                    result["ctps"] = f"{m.group(1)} s√©rie {m.group(2)}"
                else:
                    result["ctps"] = m.group(1)
                logger.info(f"[OCR_LABOR] CTPS: {result['ctps']}")
                break
        
        logger.info(f"[OCR_LABOR] ‚úÖ Extra√≠dos {len(result)} campos via OCR")
        return result
        
    except Exception as e:
        logger.error(f"[OCR_LABOR] ‚ùå Erro: {e}")
        return result


def extract_text_from_annex_pages(pdf_path: str, last_pages: int = 5) -> str:
    """
    Extrai texto via OCR das √öLTIMAS p√°ginas do PDF (onde est√£o anexos como TRCT/contracheques).
    
    2025-11-28: Fun√ß√£o criada para resolver problema de PDFs h√≠bridos:
    - Peti√ß√£o inicial nas primeiras p√°ginas (texto nativo)
    - Anexos (TRCT, contracheques) nas √∫ltimas p√°ginas (escaneados/imagens)
    
    Args:
        pdf_path: Caminho do arquivo PDF
        last_pages: N√∫mero de p√°ginas finais para processar (default: 5)
    
    Returns:
        Texto extra√≠do via OCR das √∫ltimas p√°ginas
    """
    try:
        from PyPDF2 import PdfReader
        
        reader = PdfReader(pdf_path)
        total_pages = len(reader.pages)
        
        if total_pages <= last_pages:
            start_page = 1
        else:
            start_page = total_pages - last_pages + 1
        
        logger.info(f"[OCR_ANNEX] Processando p√°ginas {start_page}-{total_pages} de {total_pages}")
        
        images = convert_from_path(
            pdf_path, 
            dpi=150,
            first_page=start_page,
            last_page=total_pages,
            poppler_path=POPPLER_PATH
        )
        
        texto_completo = []
        for i, img in enumerate(images, start_page):
            img_gray = img.convert('L')
            config = '--psm 6 -l por+eng'
            texto_pagina = pytesseract.image_to_string(img_gray, config=config)
            
            if texto_pagina and len(texto_pagina.strip()) > 50:
                texto_completo.append(f"\n--- ANEXO P√ÅGINA {i} (OCR) ---\n{texto_pagina}")
                logger.debug(f"[OCR_ANNEX] P√°gina {i}: {len(texto_pagina)} chars")
        
        texto_final = "\n".join(texto_completo)
        logger.info(f"[OCR_ANNEX] ‚úÖ Extra√ß√£o de anexos: {len(texto_final)} chars")
        
        return texto_final
        
    except Exception as e:
        logger.error(f"[OCR_ANNEX] ‚ùå Erro ao processar anexos: {e}")
        return ""


def _parse_sumario_for_annex_ranges(reader, scanned_pages: List[int]) -> Dict[str, List[int]]:
    """
    Analisa p√°ginas de sum√°rio/√≠ndice para inferir quais p√°ginas escaneadas 
    correspondem a cada tipo de documento.
    
    Estrat√©gia: O sum√°rio lista documentos em ordem. Identificamos a ordem
    e mapeamos para as p√°ginas escaneadas na mesma sequ√™ncia.
    """
    import re
    
    annex_order = []
    
    for i, page in enumerate(reader.pages):
        text = page.extract_text() or ""
        text_lower = text.lower()
        
        if "sum√°rio" in text_lower or "documentos" in text_lower:
            lines = text.split('\n')
            for line in lines:
                line_lower = line.lower()
                if "trct" in line_lower or "termo de rescis" in line_lower:
                    annex_order.append('trct')
                elif any(kw in line_lower for kw in ["contracheque", "holerite", "recibo de"]):
                    annex_order.append('contracheque')
                elif "ficha de registro" in line_lower:
                    annex_order.append('ficha_registro')
                elif "ctps" in line_lower or "carteira de trabalho" in line_lower:
                    annex_order.append('ctps')
    
    result = {'trct': [], 'contracheque': [], 'ficha_registro': [], 'ctps': []}
    
    if annex_order and scanned_pages:
        pages_per_annex = max(1, len(scanned_pages) // max(1, len(annex_order)))
        
        for idx, annex_type in enumerate(annex_order):
            start_idx = idx * pages_per_annex
            end_idx = min(start_idx + pages_per_annex, len(scanned_pages))
            if start_idx < len(scanned_pages):
                result[annex_type].extend(scanned_pages[start_idx:end_idx])
    
    return result


def map_pdf_annexes(pdf_path: str) -> Dict[str, List[int]]:
    """
    MAPEAMENTO CIR√öRGICO: Identifica localiza√ß√£o exata de cada tipo de anexo no PDF.
    
    Estrat√©gia (melhorada):
    1. Analisa texto nativo de cada p√°gina para identificar tipo de documento
    2. P√°ginas com < 200 chars = escaneadas (candidatas a OCR)
    3. Se n√£o encontrar tipos espec√≠ficos, usa sum√°rio para inferir ordem
    4. Fallback: divide p√°ginas escaneadas em grupos l√≥gicos
    
    Returns:
        Dict com listas de p√°ginas por tipo:
        {
            'trct': [17, 18],        # P√°ginas do TRCT
            'contracheque': [19, 20, 21],  # P√°ginas de contracheques
            'ficha_registro': [22],  # Ficha de registro
            'ctps': [23, 24],        # CTPS
            'audiencia': [35, 36],   # Notifica√ß√µes de audi√™ncia
            'scanned': [17, 18, 19, 20, 21, 22, 23, 24]  # Todas p√°ginas escaneadas
            'salary_candidates': [17, 18, 19]  # P√°ginas prov√°veis para sal√°rio
        }
    """
    from PyPDF2 import PdfReader
    
    try:
        reader = PdfReader(pdf_path)
        total_pages = len(reader.pages)
        
        mapping = {
            'trct': [],
            'contracheque': [],
            'ficha_registro': [],
            'ctps': [],
            'audiencia': [],
            'scanned': [],
            'salary_candidates': [],
            'total_pages': total_pages
        }
        
        SCANNED_THRESHOLD = 200
        
        for i, page in enumerate(reader.pages):
            page_num = i + 1
            text = page.extract_text() or ""
            text_lower = text.lower()
            text_len = len(text.strip())
            
            is_scanned = text_len < SCANNED_THRESHOLD
            
            if is_scanned:
                mapping['scanned'].append(page_num)
            
            if "termo de rescis" in text_lower or ("trct" in text_lower and "contrato" in text_lower):
                mapping['trct'].append(page_num)
            
            if any(kw in text_lower for kw in ["contracheque", "holerite", "demonstrativo de pagamento", "folha de pagamento"]):
                mapping['contracheque'].append(page_num)
            
            if "ficha de registro" in text_lower or "registro de empregado" in text_lower:
                mapping['ficha_registro'].append(page_num)
            
            if "carteira de trabalho" in text_lower or ("ctps" in text_lower and len(text_lower) > 100):
                mapping['ctps'].append(page_num)
            
            if any(kw in text_lower for kw in ["notifica√ß√£o", "audi√™ncia", "comparecimento"]):
                if "data" in text_lower and ("hora" in text_lower or ":" in text):
                    mapping['audiencia'].append(page_num)
        
        has_specific_types = any([
            [p for p in mapping['trct'] if p in mapping['scanned']],
            [p for p in mapping['contracheque'] if p in mapping['scanned']],
            [p for p in mapping['ficha_registro'] if p in mapping['scanned']],
            [p for p in mapping['ctps'] if p in mapping['scanned']]
        ])
        
        if not has_specific_types and mapping['scanned']:
            inferred = _parse_sumario_for_annex_ranges(reader, mapping['scanned'])
            for key in ['trct', 'contracheque', 'ficha_registro', 'ctps']:
                if inferred.get(key):
                    mapping[key] = inferred[key]
        
        if mapping['scanned']:
            scanned = mapping['scanned']
            
            if len(scanned) <= 10:
                mapping['salary_candidates'] = scanned[:]
            else:
                first_chunk = scanned[:5]
                
                mid_start = len(scanned) // 3
                mid_chunk = scanned[mid_start:mid_start+3]
                
                mapping['salary_candidates'] = list(set(first_chunk + mid_chunk))
                mapping['salary_candidates'].sort()
        
        scanned_count = len(mapping['scanned'])
        logger.info(f"[MAP] PDF mapeado: {total_pages} p√°ginas, {scanned_count} escaneadas")
        logger.info(f"[MAP] TRCT: {mapping['trct']}, Contracheque: {mapping['contracheque']}, Audi√™ncia: {mapping['audiencia']}")
        logger.info(f"[MAP] Candidatos sal√°rio: {mapping['salary_candidates'][:8]}")
        
        return mapping
        
    except Exception as e:
        logger.error(f"[MAP] Erro ao mapear PDF: {e}")
        return {'trct': [], 'contracheque': [], 'ficha_registro': [], 'ctps': [], 'audiencia': [], 'scanned': [], 'salary_candidates': [], 'total_pages': 0}


def extract_ocr_from_specific_pages(pdf_path: str, pages: List[int], max_pages: int = 10) -> str:
    """
    OCR CIR√öRGICO: Processa APENAS p√°ginas espec√≠ficas identificadas pelo mapeamento.
    
    Otimiza√ß√£o m√°xima:
    - Processa somente p√°ginas relevantes (n√£o o PDF inteiro)
    - Limita a max_pages para evitar processamento excessivo
    - 150dpi para balan√ßo entre qualidade e velocidade
    
    Args:
        pdf_path: Caminho do PDF
        pages: Lista de p√°ginas espec√≠ficas para processar (1-indexed)
        max_pages: Limite de p√°ginas para processar (default: 10)
    
    Returns:
        Texto extra√≠do via OCR das p√°ginas especificadas
    """
    if not pages:
        return ""
    
    pages_to_process = pages[:max_pages]
    
    try:
        texto_completo = []
        
        for page_num in pages_to_process:
            try:
                images = convert_from_path(
                    pdf_path,
                    dpi=150,
                    first_page=page_num,
                    last_page=page_num,
                    poppler_path=POPPLER_PATH
                )
                
                if images:
                    img_gray = images[0].convert('L')
                    config = '--psm 6 -l por+eng'
                    texto_pagina = pytesseract.image_to_string(img_gray, config=config)
                    
                    if texto_pagina and len(texto_pagina.strip()) > 30:
                        texto_completo.append(f"\n--- P√ÅGINA {page_num} (OCR) ---\n{texto_pagina}")
                        logger.debug(f"[OCR_SURGICAL] P√°gina {page_num}: {len(texto_pagina)} chars")
                        
            except Exception as e:
                logger.warning(f"[OCR_SURGICAL] Erro na p√°gina {page_num}: {e}")
                continue
        
        texto_final = "\n".join(texto_completo)
        logger.info(f"[OCR_SURGICAL] ‚úÖ Processadas {len(pages_to_process)} p√°ginas: {len(texto_final)} chars")
        
        return texto_final
        
    except Exception as e:
        logger.error(f"[OCR_SURGICAL] ‚ùå Erro: {e}")
        return ""


def extract_salario_from_contracheque_ocr(texto: str) -> Optional[str]:
    """
    Extrai sal√°rio de texto OCR de contracheque.
    
    Prioridade:
    1. Sal√°rio Base/Sal√°rio Contratual
    2. Maior Remunera√ß√£o
    3. √öltimo sal√°rio no hist√≥rico de altera√ß√µes
    
    Padr√µes espec√≠ficos de contracheque:
    - "Sal√°rio 220,000 1.632,31" (c√≥digo + qtd + valor)
    - "Sal√°rio Base: 1.632,31"
    - "Maior Remunera√ß√£o: 2.160,31"
    - Hist√≥rico: "01/05/2025 2.255,56 2.255,56 Acordo/Convencao"
    """
    import re
    
    if not texto:
        return None
    
    texto_norm = re.sub(r'\s+', ' ', texto).strip()
    texto_norm = re.sub(r'R\s*\$', 'R$', texto_norm)
    texto_norm = re.sub(r',\s+', ',', texto_norm)
    texto_norm = re.sub(r'\.\s+', '.', texto_norm)
    texto_norm = re.sub(r'\s+\.', '.', texto_norm)
    
    valor_pattern = r'([0-9]+(?:[\.][0-9]{3})*[,][0-9]{2})'
    
    patterns_priority = [
        (r'sal[a√°]rio\s*(?:base|contratual)?[:\s]+[0-9,\.]+\s+' + valor_pattern, 'Sal√°rio Base'),
        (r'Sal\.?\s*Contr\.?\s*(?:INSS)?\s+' + valor_pattern, 'Sal. Contr.'),
        (r'maior\s*remunera[√ßc][a√£]o[:\s]+' + valor_pattern, 'Maior Remunera√ß√£o'),
        (r'(?:Total\s*)?Vencimentos[:\s]+' + valor_pattern, 'Total Vencimentos'),
    ]
    
    for pattern, name in patterns_priority:
        match = re.search(pattern, texto_norm, re.IGNORECASE)
        if match:
            valor = match.group(1)
            valor_float = float(valor.replace('.', '').replace(',', '.'))
            if 800 < valor_float < 50000:
                logger.debug(f"[OCR_CONTRA] {name}: R$ {valor}")
                return f"R$ {valor}"
    
    hist_pattern = r'(\d{2}/\d{2}/\d{4})\s+[\d/]+\s+' + valor_pattern + r'\s+' + valor_pattern
    historico = re.findall(hist_pattern, texto_norm)
    
    if historico:
        ultimo = historico[-1]
        valor = ultimo[1]
        valor_float = float(valor.replace('.', '').replace(',', '.'))
        if 800 < valor_float < 50000:
            logger.debug(f"[OCR_CONTRA] Hist√≥rico (√∫ltimo): R$ {valor}")
            return f"R$ {valor}"
    
    return None


def extract_salario_from_annexes(pdf_path: str) -> Optional[str]:
    """
    Extrai sal√°rio dos anexos do PDF (TRCT, contracheques) via OCR CIR√öRGICO.
    
    PLANO BATMAN - Estrat√©gia otimizada (v2):
    1. Mapeia estrutura do PDF para identificar p√°ginas de TRCT/contracheques
    2. Identifica p√°ginas escaneadas (< 200 chars)
    3. Usa salary_candidates que inclui p√°ginas do in√≠cio E do meio
    4. Prioriza fontes: TRCT > Contracheque > Ficha > Candidatos
    5. Se n√£o encontrar, tenta mais p√°ginas em chunks
    
    Returns:
        Sal√°rio no formato "R$ X.XXX,XX" ou None
    """
    from .regex_utils import extract_salario
    
    logger.info(f"[OCR_SURGICAL] Iniciando extra√ß√£o cir√∫rgica de sal√°rio: {pdf_path}")
    log_info("Mapeando anexos para extra√ß√£o cir√∫rgica de sal√°rio", region="OCR_EXTRACTOR")
    
    mapping = map_pdf_annexes(pdf_path)
    
    scanned_pages = set(mapping['scanned'])
    
    trct_scanned = [p for p in mapping['trct'] if p in scanned_pages]
    contracheque_scanned = [p for p in mapping['contracheque'] if p in scanned_pages]
    ficha_scanned = [p for p in mapping['ficha_registro'] if p in scanned_pages]
    ctps_scanned = [p for p in mapping['ctps'] if p in scanned_pages]
    
    pages_to_ocr = []
    source_priority = []
    
    if trct_scanned:
        pages_to_ocr.extend(trct_scanned[:3])
        source_priority.append(f"TRCT({trct_scanned[:3]})")
    if contracheque_scanned:
        pages_to_ocr.extend(contracheque_scanned[:3])
        source_priority.append(f"Contracheque({contracheque_scanned[:3]})")
    if ficha_scanned:
        pages_to_ocr.extend(ficha_scanned[:2])
        source_priority.append(f"Ficha({ficha_scanned[:2]})")
    if ctps_scanned:
        pages_to_ocr.extend(ctps_scanned[:2])
        source_priority.append(f"CTPS({ctps_scanned[:2]})")
    
    if not pages_to_ocr:
        salary_candidates = mapping.get('salary_candidates', [])
        if salary_candidates:
            pages_to_ocr = salary_candidates[:8]
            source_priority.append(f"Candidatos({len(salary_candidates)} total, processando {len(pages_to_ocr)})")
    
    if not pages_to_ocr:
        logger.info("[OCR_SURGICAL] Nenhuma p√°gina candidata identificada")
        return None
    
    pages_to_ocr = list(dict.fromkeys(pages_to_ocr))[:8]
    
    logger.info(f"[OCR_SURGICAL] Prioridade: {' > '.join(source_priority)}")
    log_info(f"OCR cir√∫rgico em {len(pages_to_ocr)} p√°ginas: {source_priority}", region="OCR_EXTRACTOR")
    
    texto_ocr = extract_ocr_from_specific_pages(pdf_path, pages_to_ocr, max_pages=8)
    
    if not texto_ocr:
        return None
    
    salario = extract_salario_from_contracheque_ocr(texto_ocr)
    
    if not salario:
        salario = extract_salario(texto_ocr)
    
    if salario:
        logger.info(f"[OCR_SURGICAL] ‚úÖ Sal√°rio extra√≠do: {salario}")
        log_info(f"Sal√°rio via OCR cir√∫rgico: {salario}", region="OCR_EXTRACTOR")
        return salario
    
    all_scanned = mapping.get('scanned', [])
    remaining = [p for p in all_scanned if p not in pages_to_ocr]
    
    if remaining and len(remaining) >= 3:
        mid_start = len(remaining) // 2
        extra_pages = remaining[mid_start:mid_start+3]
        
        logger.info(f"[OCR_SURGICAL] Tentando chunk adicional: {extra_pages}")
        texto_extra = extract_ocr_from_specific_pages(pdf_path, extra_pages, max_pages=3)
        
        if texto_extra:
            salario = extract_salario_from_contracheque_ocr(texto_extra)
            if not salario:
                salario = extract_salario(texto_extra)
            
            if salario:
                logger.info(f"[OCR_SURGICAL] ‚úÖ Sal√°rio encontrado no chunk adicional: {salario}")
                return salario
    
    logger.info("[OCR_SURGICAL] Sal√°rio n√£o encontrado em nenhuma p√°gina")
    return None


def extract_audiencia_from_mapping(pdf_path: str) -> Optional[Dict[str, str]]:
    """
    Extrai data de audi√™ncia das p√°ginas mapeadas como notifica√ß√µes.
    
    PLANO BATMAN - Estrat√©gia para audi√™ncia:
    1. Mapeia p√°ginas com notifica√ß√£o de audi√™ncia
    2. Extrai texto (nativo ou OCR se necess√°rio)
    3. Aplica regex espec√≠ficos para data/hora de audi√™ncia
    
    Returns:
        Dict com data_audiencia e hora_audiencia, ou None
    """
    import re
    
    logger.info(f"[OCR_SURGICAL] Extraindo audi√™ncia via mapeamento: {pdf_path}")
    
    mapping = map_pdf_annexes(pdf_path)
    
    audiencia_pages = mapping.get('audiencia', [])
    
    if not audiencia_pages:
        logger.info("[OCR_SURGICAL] Nenhuma p√°gina de audi√™ncia identificada no mapeamento")
        return None
    
    from PyPDF2 import PdfReader
    
    try:
        reader = PdfReader(pdf_path)
        
        patterns_data = [
            r'(?:designad[ao]|marcad[ao]|realiz[ao]r)[^0-9]{0,30}(\d{1,2})[/.-](\d{1,2})[/.-](\d{2,4})',
            r'(?:dia|data)[:\s]*(\d{1,2})[/.-](\d{1,2})[/.-](\d{2,4})',
            r'(\d{1,2})\s+de\s+(\w+)\s+de\s+(\d{4})',
            r'comparec\w+[^0-9]{0,30}(\d{1,2})[/.-](\d{1,2})[/.-](\d{2,4})',
        ]
        
        patterns_hora = [
            r'(?:√†s|as|hora)[:\s]*(\d{1,2})[h:](\d{2})',
            r'(\d{1,2})[h:](\d{2})\s*(?:h|hora|min)',
            r'hor√°rio[:\s]*(\d{1,2})[h:](\d{2})',
        ]
        
        meses = {
            'janeiro': '01', 'fevereiro': '02', 'mar√ßo': '03', 'abril': '04',
            'maio': '05', 'junho': '06', 'julho': '07', 'agosto': '08',
            'setembro': '09', 'outubro': '10', 'novembro': '11', 'dezembro': '12'
        }
        
        for page_num in audiencia_pages:
            if page_num > len(reader.pages):
                continue
                
            page = reader.pages[page_num - 1]
            text = page.extract_text() or ""
            
            if len(text.strip()) < 100:
                ocr_text = extract_ocr_from_specific_pages(pdf_path, [page_num], max_pages=1)
                if ocr_text:
                    text = ocr_text
            
            text_lower = text.lower()
            
            data_encontrada = None
            hora_encontrada = None
            
            for pattern in patterns_data:
                match = re.search(pattern, text_lower, re.IGNORECASE)
                if match:
                    groups = match.groups()
                    if len(groups) == 3:
                        dia, mes_ou_nome, ano = groups
                        
                        if mes_ou_nome in meses:
                            mes = meses[mes_ou_nome]
                        else:
                            mes = mes_ou_nome
                        
                        if len(str(ano)) == 2:
                            ano = f"20{ano}"
                        
                        data_encontrada = f"{dia.zfill(2)}/{mes.zfill(2)}/{ano}"
                        break
            
            for pattern in patterns_hora:
                match = re.search(pattern, text_lower, re.IGNORECASE)
                if match:
                    hora, minuto = match.groups()
                    hora_encontrada = f"{hora.zfill(2)}:{minuto}"
                    break
            
            if data_encontrada:
                logger.info(f"[OCR_SURGICAL] ‚úÖ Audi√™ncia encontrada p√°gina {page_num}: {data_encontrada} {hora_encontrada or ''}")
                return {
                    'data_audiencia': data_encontrada,
                    'hora_audiencia': hora_encontrada
                }
        
        logger.info("[OCR_SURGICAL] Audi√™ncia n√£o encontrada nas p√°ginas mapeadas")
        return None
        
    except Exception as e:
        logger.error(f"[OCR_SURGICAL] Erro ao extrair audi√™ncia: {e}")
        return None


def extract_pis_ctps_from_annexes(pdf_path: str) -> Dict[str, Optional[str]]:
    """
    Extrai PIS e CTPS de anexos escaneados (CTPS, TRCT, Ficha de Registro).
    
    PLANO BATMAN - OCR cir√∫rgico para campos de identifica√ß√£o:
    1. Mapeia estrutura do PDF para identificar p√°ginas de CTPS/TRCT/Ficha
    2. Identifica p√°ginas escaneadas (< 200 chars)
    3. Faz OCR apenas nas p√°ginas relevantes
    4. Aplica regex espec√≠ficos para PIS e CTPS
    
    Args:
        pdf_path: Caminho do arquivo PDF
    
    Returns:
        Dict com 'pis' e 'ctps' extra√≠dos via OCR
    """
    import re
    from .regex_utils import extract_pis, extract_ctps
    
    logger.info(f"[OCR_SURGICAL] Iniciando extra√ß√£o de PIS/CTPS dos anexos: {pdf_path}")
    log_info("Mapeando anexos para extra√ß√£o cir√∫rgica de PIS/CTPS", region="OCR_EXTRACTOR")
    
    result = {'pis': None, 'ctps': None}
    
    try:
        mapping = map_pdf_annexes(pdf_path)
        scanned_pages = set(mapping.get('scanned', []))
        
        # P√°ginas priorit√°rias para PIS/CTPS (ordem de prioridade)
        priority_sources = [
            ('trct', mapping.get('trct', []), 3),       # TRCT tem PIS/CTPS
            ('ctps', mapping.get('ctps', []), 3),       # CTPS f√≠sica tem n√∫mero
            ('ficha_registro', mapping.get('ficha_registro', []), 2),  # Ficha tem PIS
        ]
        
        pages_to_ocr = []
        for source_name, pages, max_pages in priority_sources:
            scanned = [p for p in pages if p in scanned_pages]
            if scanned:
                pages_to_ocr.extend(scanned[:max_pages])
                logger.debug(f"[OCR_SURGICAL] {source_name}: {scanned[:max_pages]}")
        
        # Limitar a 8 p√°ginas para performance
        pages_to_ocr = list(dict.fromkeys(pages_to_ocr))[:8]
        
        # üÜï FALLBACK: Se n√£o encontrou p√°ginas mapeadas, usar as √∫ltimas N p√°ginas escaneadas
        # 2025-11-28: Muitos PDFs t√™m anexos no final que n√£o s√£o detectados por keywords
        if not pages_to_ocr and scanned_pages:
            # Ordenar e pegar as √∫ltimas 5 p√°ginas escaneadas
            sorted_scanned = sorted(scanned_pages)
            pages_to_ocr = sorted_scanned[-5:] if len(sorted_scanned) > 5 else sorted_scanned
            logger.info(f"[OCR_SURGICAL] Fallback: usando √∫ltimas {len(pages_to_ocr)} p√°ginas escaneadas: {pages_to_ocr}")
        
        if not pages_to_ocr:
            logger.info("[OCR_SURGICAL] Nenhuma p√°gina escaneada encontrada para OCR")
            return result
        
        logger.info(f"[OCR_SURGICAL] Processando {len(pages_to_ocr)} p√°ginas: {pages_to_ocr}")
        
        # OCR nas p√°ginas selecionadas
        texto_ocr = extract_ocr_from_specific_pages(pdf_path, pages_to_ocr, max_pages=8)
        
        if not texto_ocr or len(texto_ocr.strip()) < 50:
            logger.info("[OCR_SURGICAL] OCR retornou texto insuficiente")
            return result
        
        logger.debug(f"[OCR_SURGICAL] OCR extraiu {len(texto_ocr)} chars")
        
        # Extrair PIS
        pis = extract_pis(texto_ocr)
        if pis:
            result['pis'] = pis
            logger.info(f"[OCR_SURGICAL] ‚úÖ PIS encontrado: {pis}")
        
        # Extrair CTPS
        ctps = extract_ctps(texto_ocr)
        if ctps and ctps != "DIGITAL":  # Ignorar "DIGITAL"
            result['ctps'] = ctps
            logger.info(f"[OCR_SURGICAL] ‚úÖ CTPS encontrado: {ctps}")
        
        # Se n√£o encontrou CTPS com regex padr√£o, tentar padr√µes espec√≠ficos de OCR
        if not result['ctps']:
            # Padr√µes espec√≠ficos para texto OCR (mais tolerantes a erros)
            ocr_ctps_patterns = [
                r'(\d{5,8})\s*[-/]?\s*(\d{3,6})\s*[-/]?\s*([A-Z]{2})',  # 123456-789/RJ
                r'N[¬∞¬∫]?\s*(\d{5,8})',  # N¬∫ 123456
                r'(?:CTPS|Carteira)[^\d]{0,20}(\d{5,8})',  # CTPS ... 123456
            ]
            
            for pattern in ocr_ctps_patterns:
                match = re.search(pattern, texto_ocr, re.I)
                if match:
                    if match.lastindex >= 3:
                        ctps_val = f"{match.group(1)} s√©rie {match.group(2)}/{match.group(3)}"
                    else:
                        ctps_val = match.group(1)
                    
                    result['ctps'] = ctps_val
                    logger.info(f"[OCR_SURGICAL] ‚úÖ CTPS (padr√£o OCR): {ctps_val}")
                    break
        
        return result
        
    except Exception as e:
        logger.error(f"[OCR_SURGICAL] Erro na extra√ß√£o de PIS/CTPS: {e}")
        return result


def extract_fields_with_ocr(pdf_path: str) -> Dict[str, Optional[str]]:
    """
    Extrai campos trabalhistas de PDF escaneado usando OCR + regex.
    
    Args:
        pdf_path: Caminho do arquivo PDF
    
    Returns:
        Dict com campos extra√≠dos via OCR
    """
    log_info(f"Iniciando extra√ß√£o OCR para PDF escaneado: {pdf_path}", region="OCR_EXTRACTOR")
    
    from .regex_utils import (
        extract_pis, extract_ctps, extract_local_trabalho,
        extract_motivo_demissao, extract_empregador,
        extract_data_admissao, extract_data_demissao, extract_salario
    )
    
    # Extrair texto via OCR
    texto_ocr = extract_text_with_ocr(pdf_path)
    
    if not texto_ocr:
        log_error("OCR n√£o conseguiu extrair texto do PDF", region="OCR_EXTRACTOR")
        return {}
    
    # Aplicar regex patterns no texto OCR
    result = {
        'pis': extract_pis(texto_ocr),
        'ctps': extract_ctps(texto_ocr),
        'local_trabalho': extract_local_trabalho(texto_ocr),
        'motivo_demissao': extract_motivo_demissao(texto_ocr),
        'empregador': extract_empregador(texto_ocr),
        'data_admissao': extract_data_admissao(texto_ocr),
        'data_demissao': extract_data_demissao(texto_ocr),
        'salario': extract_salario(texto_ocr)
    }
    
    extracted_count = len([v for v in result.values() if v])
    log_info(f"OCR extraiu {extracted_count} campos", region="OCR_EXTRACTOR")
    
    return result
